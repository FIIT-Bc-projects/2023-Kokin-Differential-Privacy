
@article{janiesch2021machine,
  title={Machine learning and deep learning},
  author={Janiesch, Christian and Zschech, Patrick and Heinrich, Kai},
  journal={Electronic Markets},
  volume={31},
  number={3},
  pages={685--695},
  year={2021},
  publisher={Springer}
}

@inproceedings{dwork2006differential,
  title={Differential privacy},
  author={Dwork, Cynthia},
  booktitle={International colloquium on automata, languages, and programming},
  pages={1--12},
  year={2006},
  organization={Springer}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{HEINRICH2021113494,
title = {Process data properties matter: Introducing gated convolutional neural networks (GCNN) and key-value-predict attention networks (KVP) for next event prediction with deep learning},
journal = {Decision Support Systems},
volume = {143},
pages = {113494},
year = {2021},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2021.113494},
url = {https://www.sciencedirect.com/science/article/pii/S016792362100004X},
author = {Kai Heinrich and Patrick Zschech and Christian Janiesch and Markus Bonin},
keywords = {Process mining, Predictive process monitoring, Machine learning, Deep learning, Gated convolutional neural network, Key-value-predict attention network},
abstract = {Predicting next events in predictive process monitoring enables companies to manage and control processes at an early stage and reduce their action distance. In recent years, approaches have steadily moved from classical statistical methods towards the application of deep neural network architectures, which outperform the former and enable analysis without explicit knowledge of the underlying process model. While the focus of prior research was on the long short-term memory network architecture, more deep learning architectures offer promising extensions that have proven useful for other applications of sequential data. In our work, we introduce a gated convolutional neural network and a key-value-predict attention network to the task of next event prediction. In a comprehensive evaluation study on 11 real-life benchmark datasets, we show that these two novel architectures surpass prior work in 34 out of 44 metric-dataset combinations. For our evaluation, we consider the effects of process data properties, such as sparsity, variation, and repetitiveness, and discuss their impact on the prediction quality of the different deep learning architectures. Similarly, we evaluate their classification properties in terms of generalization and handling class imbalance. Our results provide guidance for researchers and practitioners alike on how to select, validate, and comprehensively benchmark (novel) predictive process monitoring models. In particular, we highlight the importance of sufficiently diverse process data properties in event logs and the comprehensive reporting of multiple performance indicators to achieve meaningful results.}
}

@article{liu2021machine,
  title={When machine learning meets privacy: A survey and outlook},
  author={Liu, Bo and Ding, Ming and Shaham, Sina and Rahayu, Wenny and Farokhi, Farhad and Lin, Zihuai},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={2},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{sarker2021machine,
  title={Machine learning: Algorithms, real-world applications and research directions},
  author={Sarker, Iqbal H},
  journal={SN computer science},
  volume={2},
  number={3},
  pages={160},
  year={2021},
  URL={https://rdcu.be/dufy6},
  publisher={Springer}
}

@article{Hernan,
author = {Miguel A. Hernán, John Hsu and Brian Healy},
title = {A Second Chance to Get Causal Inference Right: A Classification of Data Science Tasks},
journal = {CHANCE},
volume = {32},
number = {1},
pages = {42-49},
year = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/09332480.2019.1579578},
URL = {https://doi.org/10.1080/09332480.2019.1579578},
eprint = {https://doi.org/10.1080/09332480.2019.1579578}
}

@article{JIANG2020675,
title = {Supervised Machine Learning: A Brief Primer},
journal = {Behavior Therapy},
volume = {51},
number = {5},
pages = {675-687},
year = {2020},
issn = {0005-7894},
doi = {
    https://doi.org/10.1016/j.beth.2020.05.002
},
author = {Tammy Jiang and Jaimie L. Gradus and Anthony J. Rosellini},
keywords = {machine learning, supervised learning, ensemble methods},
abstract = {Machine learning is increasingly used in mental health research and has the potential to advance our understanding of how to characterize, predict, and treat mental disorders and associated adverse health outcomes (e.g., suicidal behavior). Machine learning offers new tools to overcome challenges for which traditional statistical methods are not well-suited. This paper provides an overview of machine learning with a specific focus on supervised learning (i.e., methods that are designed to predict or classify an outcome of interest). Several common supervised learning methods are described, along with applied examples from the published literature. We also provide an overview of supervised learning model building, validation, and performance evaluation. Finally, challenges in creating robust and generalizable machine learning algorithms are discussed.}
}

@article{DONG2021100379,
title = {A survey on deep learning and its applications},
journal = {Computer Science Review},
volume = {40},
pages = {100379},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2021.100379},
author = {Shi Dong and Ping Wang and Khushnood Abbas},
keywords = {Deep learning, Stacked auto encoder, Deep belief networks, Deep Boltzmann machine, Convolutional neural network},
abstract = {Deep learning, a branch of machine learning, is a frontier for artificial intelligence, aiming to be closer to its primary goal—artificial intelligence. This paper mainly adopts the summary and the induction methods of deep learning. Firstly, it introduces the global development and the current situation of deep learning. Secondly, it describes the structural principle, the characteristics, and some kinds of classic models of deep learning, such as stacked auto encoder, deep belief network, deep Boltzmann machine, and convolutional neural network. Thirdly, it presents the latest developments and applications of deep learning in many fields such as speech processing, computer vision, natural language processing, and medical applications. Finally, it puts forward the problems and the future research directions of deep learning.
           
           }
}

@InProceedings{KTENA,
author="Ktena, Sofia Ira
and Parisot, Sarah
and Ferrante, Enzo
and Rajchl, Martin
and Lee, Matthew
and Glocker, Ben
and Rueckert, Daniel",
editor="Descoteaux, Maxime
and Maier-Hein, Lena
and Franz, Alfred
and Jannin, Pierre
and Collins, D. Louis
and Duchesne, Simon",
title="Distance Metric Learning Using Graph Convolutional Networks: Application to Functional Brain Networks",
booktitle="Medical Image Computing and Computer Assisted Intervention − MICCAI 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="469--477",
abstract="Evaluating similarity between graphs is of major importance in several computer vision and pattern recognition problems, where graph representations are often used to model objects or interactions between elements. The choice of a distance or similarity metric is, however, not trivial and can be highly dependent on the application at hand. In this work, we propose a novel metric learning method to evaluate distance between graphs that leverages the power of convolutional neural networks, while exploiting concepts from spectral graph theory to allow these operations on irregular graphs. We demonstrate the potential of our method in the field of connectomics, where neuronal pathways or functional connections between brain regions are commonly modelled as graphs. In this problem, the definition of an appropriate graph similarity function is critical to unveil patterns of disruptions associated with certain brain disorders. Experimental results on the ABIDE dataset show that our method can learn a graph similarity metric tailored for a clinical application, improving the performance of a simple k-nn classifier by 11.9{\%} compared to a traditional distance metric.",
isbn="978-3-319-66182-7"
}

@Article{MA,
AUTHOR = {Ma, Xiaolei and Dai, Zhuang and He, Zhengbing and Ma, Jihui and Wang, Yong and Wang, Yunpeng},
TITLE = {Learning Traffic as Images: A Deep Convolutional Neural Network for Large-Scale Transportation Network Speed Prediction},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {818},
URL = {https://www.mdpi.com/1424-8220/17/4/818},
PubMedID = {28394270},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a convolutional neural network (CNN)-based method that learns traffic as images and predicts large-scale, network-wide traffic speed with a high accuracy. Spatiotemporal traffic dynamics are converted to images describing the time and space relations of traffic flow via a two-dimensional time-space matrix. A CNN is applied to the image following two consecutive steps: abstract traffic feature extraction and network-wide traffic speed prediction. The effectiveness of the proposed method is evaluated by taking two real-world transportation networks, the second ring road and north-east transportation network in Beijing, as examples, and comparing the method with four prevailing algorithms, namely, ordinary least squares, k-nearest neighbors, artificial neural network, and random forest, and three deep learning architectures, namely, stacked autoencoder, recurrent neural network, and long-short-term memory network. The results show that the proposed method outperforms other algorithms by an average accuracy improvement of 42.91% within an acceptable execution time. The CNN can train the model in a reasonable time and, thus, is suitable for large-scale transportation networks.},
DOI = {10.3390/s17040818}
}

@INPROCEEDINGS{DPMADEWEASY,
  author={Aitsam, Muhammad},
  booktitle={2022 International Conference on Emerging Trends in Electrical, Control, and Telecommunication Engineering (ETECTE)}, 
  title={Differential Privacy Made Easy}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/ETECTE55893.2022.10007322}}

@article{DWORK2019,
place = {Country unknown/Code not available}, title = {Differential Privacy in Practice: Expose your Epsilons!}, url = {https://par.nsf.gov/biblio/10217360}, DOI = {10.29012/jpc.689}, abstractNote = {Differential privacy is at a turning point. Implementations have been successfully leveraged in private industry, the public sector, and academia in a wide variety of applications, allowing scientists, engineers, and researchers the ability to learn about populations of interest without specifically learning about these individuals. Because differential privacy allows us to quantify cumulative privacy loss, these differentially private systems will, for the first time, allow us to measure and compare the total privacy loss due to these personal data-intensive activities. Appropriately leveraged, this could be a watershed moment for privacy. Like other technologies and techniques that allow for a range of instantiations, implementation details matter. When meaningfully implemented, differential privacy supports deep data-driven insights with minimal worst-case privacy loss. When not meaningfully implemented, differential privacy delivers privacy mostly in name. Using differential privacy to maximize learning while providing a meaningful degree of privacy requires judicious choices with respect to the privacy parameter epsilon, among other factors. However, there is little understanding of what is the optimal value of epsilon for a given system or classes of systems/purposes/data etc. or how to go about figuring it out. To understand current differential privacy implementations and how organizations make these key choices in practice, we conducted interviews with practitioners to learn from their experiences of implementing differential privacy. We found no clear consensus on how to choose epsilon, nor is there agreement on how to approach this and other key implementation decisions. Given the importance of these implementation details there is a need for shared learning amongst the differential privacy community. To serve these purposes, we propose the creation of the Epsilon Registry—a publicly available communal body of knowledge about differential privacy implementations that can be used by various stakeholders to drive the identification and adoption of judicious differentially private implementations.}, journal = {Journal of Privacy and Confidentiality}, volume = {9}, number = {2}, author = {Dwork, Cynthia and Kohli, Nitin and Mulligan, Deirdre}, editor = {null} }

@INPROCEEDINGS{ExpMechanism,
  author={McSherry, Frank and Talwar, Kunal},
  booktitle={48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)}, 
  title={Mechanism Design via Differential Privacy}, 
  year={2007},
  volume={},
  number={},
  pages={94-103},
  doi={10.1109/FOCS.2007.66}}

@inproceedings{RandRespMechanism,
  title={Using Randomized Response for Differential Privacy Preserving Data Collection.},
  author={Wang, Yue and Wu, Xintao and Hu, Donghui},
  booktitle={EDBT/ICDT Workshops},
  volume={1558},
  pages={0090--6778},
  year={2016}
}

@article{LaplaceMechanism,
  title={A secure visual cryptography scheme using private key with invariant share sizes},
  author={Al-Khalid, Rola I and Al-Dallah, Randa A and Al-Anani, Aseel M and Barham, Raghad M and Hajir, Salam I and others},
  journal={Journal of Software Engineering and Applications},
  volume={10},
  number={01},
  pages={1},
  year={2017},
  publisher={Scientific Research Publishing}
}

@article{GaussianMechanism,
  title={Generalized gaussian mechanism for differential privacy},
  author={Liu, Fang},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={31},
  number={4},
  pages={747--756},
  year={2018},
  publisher={IEEE}
}

@misc{opendp1,
  title = {{Harvard University Privacy Tools Project},
  howpublished = {https://privacytools.seas.harvard.edu/}},
  note = {(accessed on 31 December 2023}
}

@inproceedings{opendp2,
  title={Differential privacy: An economic method for choosing epsilon},
  author={Hsu, Justin and Gaboardi, Marco and Haeberlen, Andreas and Khanna, Sanjeev and Narayan, Arjun and Pierce, Benjamin C and Roth, Aaron},
  booktitle={2014 IEEE 27th Computer Security Foundations Symposium},
  pages={398--410},
  year={2014},
  organization={IEEE}
}

@article{opendp3,
author = {McSherry, Frank},
title = {Privacy Integrated Queries: An Extensible Platform for Privacy-Preserving Data Analysis},
year = {2010},
issue_date = {September 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {9},
issn = {0001-0782},
url = {https://doi.org/10.1145/1810891.1810916},
doi = {10.1145/1810891.1810916},
journal = {Commun. ACM},
month = {sep},
pages = {89–97},
numpages = {9}
}

@inproceedings{opendp4,
author = {Zhang, Dan and McKenna, Ryan and Kotsogiannis, Ios and Hay, Michael and Machanavajjhala, Ashwin and Miklau, Gerome},
title = {EKTELO: A Framework for Defining Differentially-Private Computations},
year = {2018},
isbn = {9781450347037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183713.3196921},
doi = {10.1145/3183713.3196921},
pages = {115–130},
numpages = {16},
location = {Houston, TX, USA},
series = {SIGMOD '18}
}

@inproceedings{opendp5,
  title={Architecting a Differentially Private SQL Engine.},
  author={Kotsogiannis, Ios and Tao, Yuchao and Machanavajjhala, Ashwin and Miklau, Gerome and Hay, Michael},
  booktitle={CIDR},
  year={2019}
}

@inproceedings{opendp6,
  title={Differential privacy under fire},
  author={Haeberlen, Andreas and Pierce, Benjamin C and Narayan, Arjun},
  booktitle={20th USENIX Security Symposium (USENIX Security 11)},
  year={2011}
}

@inproceedings{opendp7,
  title={LightDP: Towards automating differential privacy proofs},
  author={Zhang, Danfeng and Kifer, Daniel},
  booktitle={Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages},
  pages={888--901},
  year={2017}
}
@misc{googledp1,
  title={Enabling developers and organizations to use differential privacy},
  author={Guevara, Miguel},
  year={2019},
  publisher={Sep}
}

@misc{opacus1,
  title={{Openminded},
          howpublished={https://www.openminded.org/}},
  note={{(accessed on 31 December 2023}}
}

@inproceedings{tf-dp1,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@article{tf-dp2,
  title={Enabling fast differentially private sgd via just-in-time compilation and vectorization},
  author={Subramani, Pranav and Vadivelu, Nicholas and Kamath, Gautam},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26409--26421},
  year={2021}
}

@article{Diffprivlib1,
  title={Diffprivlib: the IBM differential privacy library},
  author={Holohan, Naoise and Braghin, Stefano and Mac Aonghusa, P{\'o}l and Levacher, Killian},
  journal={arXiv preprint arXiv:1907.02444},
  year={2019}
}

@misc{Diffprivlib2,
  title={{Diffprivlib},
          howpublished={https://github.com/IBM/differential-privacy-library}},
  note={{(accessed on 31 December 2023}}
}

@article{chorus1,
  title={Chorus: Differential privacy via query rewriting},
  author={Johnson, Noah and Near, Joseph P and Hellerstein, Joseph M and Song, Dawn},
  journal={arXiv preprint arXiv:1809.07750},
  pages={30},
  year={2018}
}

@inproceedings{chorus2,
  title={Chorus: a programming framework for building scalable differential privacy mechanisms},
  author={Johnson, Noah and Near, Joseph P and Hellerstein, Joseph M and Song, Dawn},
  booktitle={2020 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={535--551},
  year={2020},
  organization={IEEE}
}

@article{zhang2023evaluation,
  title={Evaluation of Open-Source Tools for Differential Privacy},
  author={Zhang, Shiliang and Hagermalm, Anton and Slavnic, Sanjin and Schiller, Elad Michael and Almgren, Magnus},
  journal={Sensors},
  volume={23},
  number={14},
  pages={6509},
  year={2023},
  publisher={MDPI}
}

@misc{Baidu,
title={{Baidu Research},
          howpublished={http://research.baidu.com/Index}},
  note={{(accessed on 1 January 2024}}

}